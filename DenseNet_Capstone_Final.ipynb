{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet_Capstone_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1y5kNFR8x2A-QcHZYGVnoWkqZrjzEDoiP",
      "authorship_tag": "ABX9TyPdQGBRU6mwBvZnYbGumtT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PulkitAppz/Capstone_AIML_19B/blob/master/DenseNet_Capstone_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAVv6nNV3L9a",
        "outputId": "4c16f996-0690-4707-d98c-3e9bfd9b34e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Installing pydicom to read dcm files\n",
        "!pip install -q pydicom"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 35.5MB 97kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouUeQAZL3nU6"
      },
      "source": [
        "# IMPORT PACKAGES\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random, csv\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "# MODEL METRICS\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-235IvE4eQN",
        "outputId": "f600658a-7ed1-4761-fe06-aba0ca6033c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Set path to G-Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(os. getcwd())\n",
        "print(os.listdir())\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Capstone')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "['.config', 'drive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoH8B4NG4BVC"
      },
      "source": [
        "# Reading data from updated Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLhfW4iT3nfM"
      },
      "source": [
        "data_df = pd.read_csv(('updated_dataframe.csv'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtdErKkL3oD4",
        "outputId": "9d6f6617-f861-4f28-ddc9-b6f1db62cd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "display(data_df.shape, data_df.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(30227, 12)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>patientId</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>Target</th>\n",
              "      <th>class</th>\n",
              "      <th>PathName</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "      <td>stage_2_train_images/0004cfab-14fd-4e49-80ba-6...</td>\n",
              "      <td>51</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "      <td>stage_2_train_images/00313ee0-9eaa-42f4-b0ab-c...</td>\n",
              "      <td>48</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "      <td>stage_2_train_images/00322d4d-1c29-4943-afc9-b...</td>\n",
              "      <td>19</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>stage_2_train_images/003d8fa0-6bf1-40ed-b54c-a...</td>\n",
              "      <td>28</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>264.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Lung Opacity</td>\n",
              "      <td>stage_2_train_images/00436515-870c-4b36-a041-d...</td>\n",
              "      <td>32</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ... Age  Gender\n",
              "0           0             0  ...  51       F\n",
              "1           1             1  ...  48       F\n",
              "2           2             2  ...  19       M\n",
              "3           3             3  ...  28       M\n",
              "4           4             4  ...  32       F\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVjqmjgO3oBT",
        "outputId": "1855f2cd-48c2-440d-c2b2-ab99790631f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# A dataframe with paths, classes and targets\n",
        "print('Prepare a dataframe with paths, classes and targets'); print('--'*40)\n",
        "path_class_target = data_df[['patientId', 'PathName', 'class', 'Target']].copy(deep = True)\n",
        "path_class_target['PathName'] = (path_class_target['PathName']\n",
        "                             .str.replace('stage_2_train_images', 'stage_2_train_images_png')\n",
        "                             .str.replace('.dcm', '.png'))\n",
        "\n",
        "path_class_target.drop_duplicates(inplace = True)\n",
        "display(path_class_target.shape, path_class_target.nunique())\n",
        "print('\\nDistribution of target and classes')\n",
        "display(path_class_target['Target'].value_counts())\n",
        "print()\n",
        "display(path_class_target['class'].value_counts())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepare a dataframe with paths, classes and targets\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(26684, 4)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "patientId    26684\n",
              "PathName     26684\n",
              "class            3\n",
              "Target           2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Distribution of target and classes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    20672\n",
              "1     6012\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "No Lung Opacity / Not Normal    11821\n",
              "Normal                           8851\n",
              "Lung Opacity                     6012\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YclyWjM_3n8k",
        "outputId": "7bb1f3f7-7b63-40c1-ef9a-2f5fea1b2592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "path_class_target.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patientId</th>\n",
              "      <th>PathName</th>\n",
              "      <th>class</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
              "      <td>stage_2_train_images_png/0004cfab-14fd-4e49-80...</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
              "      <td>stage_2_train_images_png/00313ee0-9eaa-42f4-b0...</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
              "      <td>stage_2_train_images_png/00322d4d-1c29-4943-af...</td>\n",
              "      <td>No Lung Opacity / Not Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
              "      <td>stage_2_train_images_png/003d8fa0-6bf1-40ed-b5...</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
              "      <td>stage_2_train_images_png/00436515-870c-4b36-a0...</td>\n",
              "      <td>Lung Opacity</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              patientId  ... Target\n",
              "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6  ...      0\n",
              "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd  ...      0\n",
              "2  00322d4d-1c29-4943-afc9-b6754be640eb  ...      0\n",
              "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5  ...      0\n",
              "4  00436515-870c-4b36-a041-de91049b9ab4  ...      1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CuQV4TkNauz",
        "outputId": "eeb7c4bc-8356-4aaf-8067-e86dbebf1673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "# run to convert dcm to png or jpg.\n",
        "'''import pydicom as dicom\n",
        "import os\n",
        "import cv2\n",
        "import PIL # optional\n",
        "# make it True if you want in PNG format\n",
        "PNG = True\n",
        "# Specify the .dcm folder path\n",
        "folder_path = \"stage_2_train_images\"\n",
        "# Specify the output jpg/png folder path\n",
        "jpg_folder_path = \"stage_2_train_images_png\"\n",
        "images_path = os.listdir(folder_path)\n",
        "for n, image in enumerate(images_path):\n",
        "    ds = dicom.dcmread(os.path.join(folder_path, image))\n",
        "    pixel_array_numpy = ds.pixel_array\n",
        "    if PNG == False:\n",
        "        image = image.replace('.dcm', '.jpg')\n",
        "    else:\n",
        "        image = image.replace('.dcm', '.png')\n",
        "    cv2.imwrite(os.path.join(jpg_folder_path, image), pixel_array_numpy)\n",
        "    if n % 1000 == 0:\n",
        "        print('{} image converted'.format(n))'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import pydicom as dicom\\nimport os\\nimport cv2\\nimport PIL # optional\\n# make it True if you want in PNG format\\nPNG = True\\n# Specify the .dcm folder path\\nfolder_path = \"stage_2_train_images\"\\n# Specify the output jpg/png folder path\\njpg_folder_path = \"stage_2_train_images_png\"\\nimages_path = os.listdir(folder_path)\\nfor n, image in enumerate(images_path):\\n    ds = dicom.dcmread(os.path.join(folder_path, image))\\n    pixel_array_numpy = ds.pixel_array\\n    if PNG == False:\\n        image = image.replace(\\'.dcm\\', \\'.jpg\\')\\n    else:\\n        image = image.replace(\\'.dcm\\', \\'.png\\')\\n    cv2.imwrite(os.path.join(jpg_folder_path, image), pixel_array_numpy)\\n    if n % 1000 == 0:\\n        print(\\'{} image converted\\'.format(n))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itHecQUX8rc1"
      },
      "source": [
        "# Splitting data into Train, test and validate sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ6oAs_N3n4o"
      },
      "source": [
        "image_list = list(path_class_target['PathName'])\n",
        "random.shuffle(image_list)\n",
        "val_size = round(len(image_list)/10)\n",
        "test_size = round(len(image_list)/10)\n",
        "train_size = len(image_list)-test_size-val_size\n",
        "\n",
        "X_train = image_list[:train_size]\n",
        "X_valid = image_list[train_size:(train_size + val_size)]\n",
        "X_test = image_list[(train_size + val_size):]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrdCcbHw3n1V",
        "outputId": "4de80c60-2493-4f1f-dc5d-cbf09a7c38a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df_train = (path_class_target.merge(pd.Series(X_train, name = 'PathName'), \n",
        "                                    on = 'PathName', \n",
        "                                    how = 'right')\n",
        "          .drop(['class'], axis = 1))\n",
        "\n",
        "df_valid = (path_class_target.merge(pd.Series(X_valid, name = 'PathName'), \n",
        "                                    on = 'PathName', \n",
        "                                    how = 'right')\n",
        "          .drop(['class'], axis = 1))\n",
        "\n",
        "df_test = (path_class_target.merge(pd.Series(X_test, name = 'PathName'), \n",
        "                                    on = 'PathName', \n",
        "                                    how = 'right')\n",
        "          .drop(['class'], axis = 1))\n",
        "\n",
        "print('Shape of the dataframes:\\nTRAIN:{}\\nVALID:{}\\nTEST:{}'.format(df_train.shape, df_valid.shape, df_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the dataframes:\n",
            "TRAIN:(21348, 3)\n",
            "VALID:(2668, 3)\n",
            "TEST:(2668, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wCN4sbdF3E3",
        "outputId": "6c73524e-16e8-47f1-f8f2-b4b4fdb42412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print('Training, Validation and Test set is ~equally distributed on target'); print('--'*40)\n",
        "print('Distribution of target in the training set:'); \n",
        "display(pd.Series(df_train['Target']).value_counts(normalize = True).round(2))\n",
        "print('\\nDistribution of target in the validation set:'); \n",
        "display(pd.Series(df_valid['Target']).value_counts(normalize = True).round(2))\n",
        "print('\\nDistribution of target in the test set:'); \n",
        "display(pd.Series(df_test['Target']).value_counts(normalize = True).round(2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training, Validation and Test set is ~equally distributed on target\n",
            "--------------------------------------------------------------------------------\n",
            "Distribution of target in the training set:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    0.78\n",
              "1    0.22\n",
              "Name: Target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Distribution of target in the validation set:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    0.77\n",
              "1    0.23\n",
              "Name: Target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Distribution of target in the test set:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    0.77\n",
              "1    0.23\n",
              "Name: Target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1I2FDKz9_U7"
      },
      "source": [
        "# Dense Net 121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OoR_0WiEvA-"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from skimage.transform import resize\n",
        "import math"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6FE1tDcxBO2",
        "outputId": "05351121-0a98-4a3c-bd9b-eaa2e588fbe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7E66xzj3nxY"
      },
      "source": [
        "# Model Parameters\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 224\n",
        "EPOCH = 5\n",
        "LEARNING_RATE = 1e-4\n",
        "MONITOR = 'val_loss'\n",
        "MODE = 'min'\n",
        "VERBOSE = 1\n",
        "FACTOR = 0.1\n",
        "PATIENCE = 5\n",
        "COOLDOWN = 5\n",
        "Dense_MODEL = 'densenet.h5'\n",
        "LOSS = 'binary_crossentropy'\n",
        "METRICS = ['accuracy']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avODnzfu3ntq"
      },
      "source": [
        "df_train['Target'] = df_train['Target'].astype(str); \n",
        "df_valid['Target'] = df_valid['Target'].astype(str); \n",
        "df_test['Target'] = df_test['Target'].astype(str)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLZhzipmHReH",
        "outputId": "ac52177b-2ff4-4f58-e703-86157eaad98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_train['PathName'][0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stage_2_train_images_png/00313ee0-9eaa-42f4-b0ab-c148ed3241cd.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGFj27c-DmJB"
      },
      "source": [
        "\n",
        "\n",
        "# Data generator\n",
        "#reference : https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "class DataGenerators:\n",
        "    def __init__(self, df_train, df_valid, df_test, batch_size, path,\n",
        "                 img_size = (224, 224), class_mode = 'binary',\n",
        "                 random_state = 2020):\n",
        "        self.df_train = df_train\n",
        "        self.df_valid = df_valid\n",
        "        self.df_test = df_test\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.path = path\n",
        "        self.class_mode = class_mode\n",
        "        \n",
        "        train_augmenter = ImageDataGenerator(\n",
        "            preprocessing_function = preprocess_input,\n",
        "            rotation_range = 20, width_shift_range = 0.2,\n",
        "            height_shift_range = 0.2, zoom_range = 0.2,\n",
        "            horizontal_flip = True, rescale = 1/255.\n",
        "            )\n",
        "        \n",
        "\n",
        "      \n",
        "        \n",
        "        valid_augmenter = ImageDataGenerator(\n",
        "            preprocessing_function = preprocess_input, \n",
        "            rescale = 1/255.\n",
        "            )\n",
        "        \n",
        "        test_augmenter = ImageDataGenerator(\n",
        "            preprocessing_function = preprocess_input,\n",
        "            rescale = 1/255.\n",
        "            )\n",
        "        \n",
        "        print('Train Generator Created', '**'*20)\n",
        "        print(self.path)\n",
        "        self.train_generator = train_augmenter.flow_from_dataframe(\n",
        "  \n",
        "            x_col = 'PathName',\n",
        "            y_col = 'Target',\n",
        "            dataframe = self.df_train,\n",
        "            batch_size = self.batch_size,\n",
        "            target_size = self.img_size,\n",
        "            directory = None,\n",
        "            class_mode = self.class_mode,\n",
        "            seed = random_state,\n",
        "            shuffle = True\n",
        "            )\n",
        "        print('Validation Generator Created', '**'*20)\n",
        "        self.valid_generator = valid_augmenter.flow_from_dataframe(\n",
        "            x_col = 'PathName',\n",
        "            y_col = 'Target',\n",
        "            dataframe = self.df_valid,\n",
        "            batch_size = self.batch_size,\n",
        "            target_size = self.img_size,\n",
        "            directory = None,\n",
        "            class_mode = self.class_mode,\n",
        "            seed = random_state,\n",
        "            shuffle = False\n",
        "            )\n",
        "        print('Test Generator Created', '**'*20)\n",
        "        self.test_generator = test_augmenter.flow_from_dataframe(\n",
        "            x_col = 'PathName',\n",
        "            y_col = 'Target',\n",
        "            dataframe = self.df_test,\n",
        "            batch_size = self.batch_size,\n",
        "            target_size = self.img_size,\n",
        "            directory = None,\n",
        "            class_mode = self.class_mode,\n",
        "            seed = random_state,\n",
        "            shuffle = False\n",
        "            )\n",
        "        \n",
        "        self.step_size_train = math.ceil(\n",
        "            self.train_generator.n//self.train_generator.batch_size + 1\n",
        "            )\n",
        "        self.step_size_valid = math.ceil(\n",
        "            self.valid_generator.n//self.valid_generator.batch_size + 1\n",
        "            )\n",
        "        self.step_size_test = math.ceil(\n",
        "            self.test_generator.n//self.test_generator.batch_size + 1\n",
        "            )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOM-C02V3nSB",
        "outputId": "8023d70f-2bc9-4f28-bcea-8e85449c26f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "generators = DataGenerators(df_train, df_valid, df_test, \n",
        "                            batch_size = BATCH_SIZE, \n",
        "                            path = 'stage_2_train_images_png/', \n",
        "                            img_size = (IMAGE_SIZE, IMAGE_SIZE), \n",
        "                            class_mode = 'binary',\n",
        "                            random_state = 2020)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Generator Created ****************************************\n",
            "stage_2_train_images_png/\n",
            "Found 21348 validated image filenames belonging to 2 classes.\n",
            "Validation Generator Created ****************************************\n",
            "Found 2668 validated image filenames belonging to 2 classes.\n",
            "Test Generator Created ****************************************\n",
            "Found 2668 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hzi1ri3nF-"
      },
      "source": [
        "def build_model():\n",
        "    print('Create a `DenseNet121` model'); print('--'*40)\n",
        "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "    inputs = Input(shape = input_shape)\n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "    \n",
        "    base_model = DenseNet121(include_top = False, input_tensor = inputs, weights ='imagenet')\n",
        "    \n",
        "    densenet = Model(inputs = inputs, outputs = base_model.layers[-1].output, name = 'DenseNet121')\n",
        "    \n",
        "    model = Sequential(name = 'DenseNet121')\n",
        "    model.add(densenet)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation = 'sigmoid', kernel_initializer = initializer))\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def callbacks():\n",
        "    lrscheduler = ReduceLROnPlateau(monitor = MONITOR, factor = FACTOR, \n",
        "                                    patience = PATIENCE, verbose = VERBOSE, \n",
        "                                    mode = MODE, cooldown = COOLDOWN)\n",
        "    \n",
        "    model.compile(optimizer = Adam(lr = LEARNING_RATE), loss = LOSS, metrics = METRICS)\n",
        "    \n",
        "    cp = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor = MONITOR, \n",
        "                         verbose = VERBOSE, save_best_only = True, mode = 'min')\n",
        "    \n",
        "    \n",
        "    \n",
        "    callbacks = [cp, lrscheduler]\n",
        "    return callbacks\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CCQJJTxt8j3",
        "outputId": "bc19808e-8bbb-44a6-e2fa-129e6e481166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = build_model()\n",
        "callbacks = callbacks()\n",
        "train_generator = generators.train_generator\n",
        "validation_generator = generators.valid_generator\n",
        "test_generator = generators.test_generator  "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create a `DenseNet121` model\n",
            "--------------------------------------------------------------------------------\n",
            "Model: \"DenseNet121\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "DenseNet121 (Functional)     (None, 7, 7, 1024)        7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 7,038,529\n",
            "Trainable params: 6,954,881\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFnXbgfvcnNz",
        "outputId": "81c7a380-aabe-42d4-a842-610859622ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "  \n",
        "history = model.fit_generator(generator = train_generator, \n",
        "                                  steps_per_epoch = generators.step_size_train,\n",
        "                                  epochs = EPOCH, verbose = VERBOSE, \n",
        "                                  callbacks = callbacks,\n",
        "                                  validation_data = validation_generator, \n",
        "                                  validation_steps = generators.step_size_valid)\n",
        "print('Save the final weights'); print('--'*40)\n",
        "model.save(Dense_MODEL)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create a `DenseNet121` model\n",
            "--------------------------------------------------------------------------------\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 1s 0us/step\n",
            "Model: \"DenseNet121\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "DenseNet121 (Functional)     (None, 7, 7, 1024)        7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 7,038,529\n",
            "Trainable params: 6,954,881\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From <ipython-input-20-42484810e52d>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/5\n",
            "668/668 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.7974 \n",
            "Epoch 00001: val_loss improved from inf to 0.50328, saving model to model-0.45.h5\n",
            "668/668 [==============================] - 11586s 17s/step - loss: 0.4471 - accuracy: 0.7974 - val_loss: 0.5033 - val_accuracy: 0.7864\n",
            "Epoch 2/5\n",
            "668/668 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8341\n",
            "Epoch 00002: val_loss improved from 0.50328 to 0.36856, saving model to model-0.37.h5\n",
            "668/668 [==============================] - 6177s 9s/step - loss: 0.3720 - accuracy: 0.8341 - val_loss: 0.3686 - val_accuracy: 0.8478\n",
            "Epoch 3/5\n",
            "668/668 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8394\n",
            "Epoch 00003: val_loss improved from 0.36856 to 0.36344, saving model to model-0.36.h5\n",
            "668/668 [==============================] - 6094s 9s/step - loss: 0.3605 - accuracy: 0.8394 - val_loss: 0.3634 - val_accuracy: 0.8400\n",
            "Epoch 4/5\n",
            "668/668 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.8389\n",
            "Epoch 00004: val_loss improved from 0.36344 to 0.34761, saving model to model-0.35.h5\n",
            "668/668 [==============================] - 5941s 9s/step - loss: 0.3547 - accuracy: 0.8389 - val_loss: 0.3476 - val_accuracy: 0.8564\n",
            "Epoch 5/5\n",
            "668/668 [==============================] - ETA: 0s - loss: 0.3478 - accuracy: 0.8454\n",
            "Epoch 00005: val_loss improved from 0.34761 to 0.34195, saving model to model-0.35.h5\n",
            "668/668 [==============================] - 6065s 9s/step - loss: 0.3478 - accuracy: 0.8454 - val_loss: 0.3419 - val_accuracy: 0.8523\n",
            "Save the final weights\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdxZp7Q2qcme",
        "outputId": "c29d6681-822d-415a-e895-ec3bd7b28c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create a `DenseNet121` model\n",
            "--------------------------------------------------------------------------------\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"DenseNet121\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "DenseNet121 (Functional)     (None, 7, 7, 1024)        7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 7,038,529\n",
            "Trainable params: 6,954,881\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "humWZz2TqcXY"
      },
      "source": [
        "model.load_weights(Dense_MODEL)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5BqMDwTyLYb"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JOPRpFDtdO6"
      },
      "source": [
        "loss, accuracy = model.evaluate_generator(generator = generators.valid_generator, \n",
        "                                          steps = generators.step_size_valid)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9FgeIemx0gX",
        "outputId": "60903d8c-1d41-436e-c58a-1f59a68926e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'Loss: {round(loss, 3)}, Accuracy: {round(float(accuracy), 3)}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.324, Accuracy: 0.861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o79ptERCyQwz",
        "outputId": "7705d0da-07de-4818-92f7-a6834a551f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Predict on the test data')\n",
        "test_generator.reset()\n",
        "test_pred_roc = model.predict_generator(generator = test_generator,\n",
        "                                        steps = generators.step_size_test,\n",
        "                                        verbose = 1)\n",
        "test_pred = []\n",
        "for i in test_pred_roc:\n",
        "    if i >= 0.5: test_pred.append(1)\n",
        "    else: test_pred.append(0)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict on the test data\n",
            "84/84 [==============================] - 33s 394ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6mu7btg3EfV",
        "outputId": "51a1fe76-0191-450b-d027-a9b262c45dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator.reset()\n",
        "valid_pred_roc = model.predict_generator(generator = validation_generator,\n",
        "                                         steps = generators.step_size_valid,\n",
        "                                         verbose = 1)\n",
        "valid_pred = []\n",
        "for i in valid_pred_roc:\n",
        "    if i >= 0.5: valid_pred.append(1)\n",
        "    else: valid_pred.append(0)\n",
        "y_valid = df_valid['Target'].astype(int).values"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84/84 [==============================] - 33s 394ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5_e20yL2cCv",
        "outputId": "99676a26-beb0-404f-9e93-eae7eb75584f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(y_test, test_pred, target_names = ['Normal', 'Pneumonia']))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.88      0.95      0.91      2054\n",
            "   Pneumonia       0.76      0.56      0.64       614\n",
            "\n",
            "    accuracy                           0.86      2668\n",
            "   macro avg       0.82      0.75      0.78      2668\n",
            "weighted avg       0.85      0.86      0.85      2668\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4jv_kth5NnM",
        "outputId": "f8dfa7b8-f5a0-428f-bc36-72e73059ef39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        }
      },
      "source": [
        "print('Confusion Matrix on the test data'); print('--'*40)\n",
        "cm = confusion_matrix(y_test, test_pred)\n",
        "plot_confusion_matrix(cm, figsize = (10, 7.2), cmap = plt.cm.Reds)\n",
        "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize = 16)\n",
        "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize = 16)\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix on the test data\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x518.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3xJE-0W59Q7"
      },
      "source": [
        "# Link to weights : https://drive.google.com/file/d/1-2zo2SLekbPKbGa6IIQzJ1hBn-gG1cRw/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwznk75h6Z1j"
      },
      "source": [
        "# PNG : https://drive.google.com/drive/folders/1AT_EazfOE67zpA0J8pqjgpZsu71NzDso?usp=sharing\n",
        "\n",
        "# dataframe : https://drive.google.com/file/d/1U1WKB7p05vq8q0lIizKWq5zPzJA9u7sx/view?usp=sharing"
      ]
    }
  ]
}